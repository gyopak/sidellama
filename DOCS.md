# sidellama

## connections 

### ollama

- [install ollama](https://ollama.com/download)
- or install it with `curl -fsSL https://ollama.com/install.sh | sh`

```
# select a model from https://ollama.com/library
ollama pull phi3

# start the daemon
ollama serves
```

### LM Studio

- [install LM Studio](https://lmstudio.ai/)
- download a model
- go to `Local server` tab, hit `Start server`, and select your downloaded model

### groq

Groq offers a wide variety of models with a generous free tier.
- [Website](https://groq.com/)
- [Create an API key](https://console.groq.com/keys)